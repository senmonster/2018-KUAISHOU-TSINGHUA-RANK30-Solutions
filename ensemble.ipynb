{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C3003D6AB1244E2873DAAAF78698639",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import heamy\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from rgf.sklearn import RGFClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split, cross_val_score\n",
    "import gc\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.regularizers import l2\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "\n",
    "from keras.activations import relu\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import  StratifiedKFold, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from glmnet import LogitNet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "code",
    "code_folding": [],
    "id": "EB8AF09109854069B8EC6FBCC80C8DA3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_dataset(datatype):\n",
    "    train = pd.read_hdf('train.h5', key='train')\n",
    "    X_test = pd.read_hdf('test.h5', key='test')\n",
    "    lgbtrain_pred_fea = pd.read_hdf('pred_fea.h5', key='lgbtrain_pred_fea')\n",
    "    lgbtest_pred_fea = pd.read_hdf('pred_fea.h5', key='lgbtest_pred_fea')\n",
    "    train = pd.concat([train, lgbtrain_pred_fea], axis=1)\n",
    "    X_test = pd.concat([X_test, lgbtest_pred_fea], axis=1)\n",
    "\n",
    "    for i in list(X_test):\n",
    "        if any(t in i for t in ['gap4', '2regis']):\n",
    "            train[i] = train[i].fillna(-1)\n",
    "            X_test[i] = X_test[i].fillna(-1)\n",
    "        elif '2label' in i:\n",
    "            train[i]= train[i].fillna(17)\n",
    "            X_test[i] = X_test[i].fillna(17)\n",
    "        else:\n",
    "            train[i] = train[i].fillna(0)\n",
    "            X_test[i] = X_test[i].fillna(0)    \n",
    "    if datatype=='lgb':\n",
    "        X_train = train.drop(['label'], axis=1)\n",
    "        Y_train = train['label']\n",
    "        uid_tr = X_train['user_id']\n",
    "        uid_te = X_test['user_id']\n",
    "        del X_train['user_id'], X_test['user_id']\n",
    "        del train\n",
    "        raw_fea = list(X_train)\n",
    "        gap_fea = [i for i in raw_fea if 'gap' in i]\n",
    "        diff_fea = [i for i in raw_fea if 'diff' in i]\n",
    "        dis4label_fea = [i for i in raw_fea if '2label' in i or 'to_label' in i]\n",
    "        dis4regis_fea = [i for i in raw_fea if '2regis' in i]\n",
    "        tosel1 = gap_fea + diff_fea + dis4label_fea + dis4regis_fea\n",
    "\n",
    "        type_fea = ['register_type', 'device_type','hcc_device_type_label','hcc_register_type_label',\n",
    "                     'hcc_device_type_register_type_label']\n",
    "        pred_fea = [i for i in raw_fea if 'pred' in i]\n",
    "        count_fea = [i for i in raw_fea if i not in tosel1 + type_fea + pred_fea]\n",
    "        tosel2 = count_fea \n",
    "\n",
    "        num_fea = count_fea + ['device_type']\n",
    "        #alldata = pd.concat([X_train, X_test], ignore_index=True, axis=0)\n",
    "        num_train = len(X_train)\n",
    "        for fea in num_fea:\n",
    "            #alldata['rank_'+fea] = alldata[fea].rank(method='max')\n",
    "            X_train['rank_'+fea] = X_train[fea].rank(method='max')\n",
    "            X_test['rank_'+fea] = X_test[fea].rank(method='max')\n",
    "        rank_fea = [i for i in list(X_train) if 'rank_' in i]\n",
    "        print('rank done!')\n",
    "\n",
    "        for fea in num_fea:\n",
    "            if len(np.unique(X_train[fea])) >= 20:\n",
    "                #alldata['bin_' + fea] = pd.cut(alldata[fea], 20, right=False, labels=range(20)).astype(int)\n",
    "                X_train['bin_' + fea] = pd.cut(X_train[fea], 20, right=False, labels=range(20)).astype(int)\n",
    "                X_test['bin_' + fea] = pd.cut(X_train[fea], 20, right=False, labels=range(20)).astype(int)\n",
    "        bin_fea = [i for i in list(X_train) if 'bin_' in i]\n",
    "        print('bin done!')\n",
    "\n",
    "        for i in range(20):\n",
    "            #alldata['nbox_'+str(i)] = (alldata[bin_fea] == i).sum(axis=1)\n",
    "            X_train['nbox_'+str(i)] = (X_train[bin_fea] == i).sum(axis=1)\n",
    "            X_test['nbox_'+str(i)] = (X_test[bin_fea] == i).sum(axis=1)\n",
    "        nbox_fea = [i for i in list(X_train) if 'nbox_' in i]\n",
    "        print('count num box done')\n",
    "        #X_train = alldata.iloc[:num_train, :]\n",
    "        #X_test = alldata.iloc[num_train:, :]\n",
    "        print('final shape:', X_train.shape,X_test.shape,)\n",
    "        tosel3 = rank_fea\n",
    "        tosel4 = bin_fea + nbox_fea\n",
    "        use_fea = list(X_train)\n",
    "        return X_train, Y_train, X_test[use_fea], uid_te, tosel1, tosel2, tosel3, tosel4, type_fea, pred_fea\n",
    "    if datatype=='nn':\n",
    "        X_train = train.drop(['label'], axis=1)\n",
    "        Y_train = train['label']\n",
    "        uid_tr = X_train['user_id']\n",
    "        uid_te = X_test['user_id']\n",
    "        del X_train['user_id'], X_test['user_id']\n",
    "        del train\n",
    "        cate_col = ['register_type']\n",
    "        cont_col = [i for i in list(X_test) if i not in cate_col]\n",
    "        X_all_cont = pd.concat([X_train[cont_col], X_test[cont_col]], axis=0).reset_index(drop=True)\n",
    "        scaler = StandardScaler(with_mean=False )\n",
    "        scaler.fit(X_all_cont)\n",
    "        X_train_cont = pd.DataFrame(scaler.transform(X_train[cont_col]), columns=cont_col)\n",
    "        X_test_cont = pd.DataFrame(scaler.transform(X_test[cont_col]), columns=cont_col)\n",
    "        X_train_cont['register_type'] = X_train['register_type']\n",
    "        X_test_cont['register_type'] = X_test['register_type']\n",
    "        X_train = pd.get_dummies(X_train_cont, columns=['register_type'])\n",
    "        X_test = pd.get_dummies(X_test_cont, columns=['register_type'])\n",
    "        print('final shape:', X_train.shape, X_test.shape)\n",
    "        use_fea = list(X_train)\n",
    "        return X_train, Y_train, X_test[use_fea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9473AABA30C34FEA8847F3738938365A",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_lgb, Y_train, X_test_lgb, uid_te, tosel1, tosel2, tosel3, tosel4, type_fea, pred_fea = get_dataset('lgb')\n",
    "datalgb = Dataset(X_train_lgb, Y_train, X_test_lgb)\n",
    "\n",
    "X_train_nn, Y_train, X_test_nn = get_dataset('nn')\n",
    "datann = Dataset(X_train_nn, Y_train, X_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "8EE1D4530A0E46B98D7115431305EF11",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lgb_model(X_train, y_train, X_test, y_test=None):\n",
    "    random.seed(2018)\n",
    "    selnum1 = [int(len(tosel1) * (i/1000)) for i in range(800,950,10)]\n",
    "    random.shuffle(selnum1)\n",
    "    selnum2 = [int(len(tosel2) * (i/1000)) for i in range(800,950,10)]\n",
    "    random.shuffle(selnum2)\n",
    "    selnum3 = [int(len(tosel3) * (i/1000)) for i in range(850,960,5)]\n",
    "    random.shuffle(selnum3)\n",
    "    selnum4 = [int(len(tosel4) * (i/1000)) for i in range(200,600,5)]\n",
    "    random.shuffle(selnum4)\n",
    "    num_leaves = list(range(18, 58, 2))\n",
    "    random.shuffle(num_leaves)\n",
    "    subsample = [i/1000 for i in range(500, 800, 25)]\n",
    "    random.shuffle(subsample)\n",
    "    subsample_freq = list(range(1,5,1))\n",
    "    random.shuffle(subsample_freq)\n",
    "    reg_alpha = np.arange(0.1, 3, 0.2)\n",
    "    random.shuffle(reg_alpha)\n",
    "    reg_lambda = np.arange(0.1, 3, 0.2)\n",
    "    random.shuffle(reg_lambda)\n",
    "    colsample = [i/1000 for i in range(600, 900, 25)]\n",
    "    random.shuffle(colsample)\n",
    "    random_state = list(range(1000, 2000, 10))\n",
    "    random.shuffle(random_state)\n",
    "    min_child_weight = [1e-3, 10, 25, 35, 45, 55]\n",
    "    random.shuffle(min_child_weight)\n",
    "    min_child_samples = [10, 20, 100, 300, 500]\n",
    "    random.shuffle(min_child_samples)\n",
    "    #print(selnum1, selnum2)\n",
    "    #print(selnum3, selnum4)\n",
    "    rank_imp = np.load('rkimp.npy')\n",
    "    models = []\n",
    "    fea_choice = []\n",
    "    for i in range(6):\n",
    "        gbm = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=num_leaves[i], max_depth=-1, \n",
    "                                    learning_rate=0.01, \n",
    "                                    n_estimators=6000,\n",
    "                                    objective='binary',\n",
    "                                    min_child_weight=min_child_weight[i%6],\n",
    "                                    min_child_samples=min_child_samples[i%5],\n",
    "                                    metric = 'auc',\n",
    "                                    subsample=subsample[i], subsample_freq=subsample_freq[i%4], #.9\n",
    "                                    colsample_bytree=colsample[i], #.85\n",
    "                                    random_state=random_state[i],\n",
    "                                    reg_alpha=reg_alpha[i], reg_lambda=reg_lambda[i], \n",
    "                                     n_jobs=-1, silent=True)  \n",
    "        sel_fea = [i for i, j in rank_imp[0][:selnum1[i]]] + [i for i, j in rank_imp[1][:selnum2[i]]] +\\\n",
    "              [i for i, j in rank_imp[2][:selnum3[i]]] + [i for i, j in rank_imp[3][:selnum4[i]]] + type_fea +\\\n",
    "              pred_fea\n",
    "        models.append(gbm)\n",
    "        fea_choice.append(sel_fea)\n",
    "    #predict = np.zeros(len(X_test))\n",
    "    #for i in range(6):\n",
    "    model = models[5]\n",
    "    model.set_params(n_estimators=537)\n",
    "    model.fit(X_train[fea_choice[5]], y_train , categorical_feature=['register_type'],)\n",
    "        #eval_set=[(X_train[fea_choice[i]], y_train)], verbose=False,\n",
    "         #        early_stopping_rounds=60, eval_metric='auc')\n",
    "    predict = model.predict_proba(X_test[fea_choice[5]])[:, 1]\n",
    "    #predict /= 6\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "id": "0E56B18A18B24BDA862A8EB0B8459629",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def NN_model(X_train, y_train, X_test, y_test=None):\n",
    "    random.seed(8102)\n",
    "    num_lay1 = list(range(80, 120, 2))\n",
    "    random.shuffle(num_lay1)\n",
    "    num_lay2 = list(range(60, 100, 2))\n",
    "    random.shuffle(num_lay2)\n",
    "    num_lay3 = list(range(40, 80, 2))\n",
    "    random.shuffle(num_lay3)\n",
    "    drop1 = np.arange(0.5, 0.9, 0.05)\n",
    "    random.shuffle(drop1)\n",
    "    drop2 = np.arange(0.4, 0.8, 0.05)\n",
    "    random.shuffle(drop2)\n",
    "    drop3 = np.arange(0.2, 0.6, 0.05)\n",
    "    random.shuffle(drop3)\n",
    "    \n",
    "    nnmodels = []\n",
    "    for i in range(10):\n",
    "        nnmodel = Sequential()\n",
    "        nnmodel.add(Dense(num_lay1[i], init = 'he_normal', input_dim = X_train_nn.shape[1] ))\n",
    "        nnmodel.add(PReLU())\n",
    "        nnmodel.add(BatchNormalization())\n",
    "        nnmodel.add(Dropout(drop1[i%8]))\n",
    "            \n",
    "        nnmodel.add(Dense(num_lay2[i], init = 'he_normal'))\n",
    "        nnmodel.add(PReLU())\n",
    "        nnmodel.add(BatchNormalization())    \n",
    "        nnmodel.add(Dropout(drop2[i%8]))\n",
    "        \n",
    "        nnmodel.add(Dense(num_lay3[i], init = 'he_normal'))\n",
    "        nnmodel.add(PReLU())\n",
    "        nnmodel.add(BatchNormalization())    \n",
    "        nnmodel.add(Dropout(drop3[i%8]))\n",
    "        \n",
    "        nnmodel.add(Dense(1, init='he_normal', activation='sigmoid'))\n",
    "        \n",
    "        nnmodel.compile(loss='binary_crossentropy',optimizer='adam') \n",
    "        nnmodels.append(nnmodel)\n",
    "    predict = np.zeros(len(X_test))\n",
    "    for i in range(10):\n",
    "        nnmodel = nnmodels[i]\n",
    "        nnmodel.fit(X_train, y_train, epochs=100, batch_size=4096,\n",
    "            validation_data=(X_train, y_train),\n",
    "            callbacks= [EarlyStopping(monitor='val_loss',patience=3, verbose=20) ], verbose = 20\n",
    "            )\n",
    "        predict += nnmodel.predict(X_test).ravel()\n",
    "    predict /= 10\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7412410FAA704E86BE9D5916E846F7EC",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_lgb = Regressor( dataset=datalgb, estimator=lgb_model, use_cache=False)\n",
    "clf_nn = Regressor( dataset=datann, estimator=NN_model, use_cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "507CD9A511DF4A1F9C6AA3EA6B799CBB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X_train_nn, Y_train, test_size = 0.2,\n",
    "        random_state=1, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0E8AAF05593C4C298A4E12EDCDD73ABE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res_lgb = clf_lgb.validate(roc_auc_score,indices=(x_train.index, x_test.index))\n",
    "# 0.8920810632489799\n",
    "\n",
    "res_nn = clf_nn.validate(roc_auc_score, indices=(x_train.index, x_test.index))\n",
    "# ccuracy: 0.8916403498422563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F19C7E19387F486F97A6834F6CD39146",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline = ModelsPipeline(clf_lgb, clf_nn )\n",
    "#weights = pipeline.find_weights(roc_auc_score,)\n",
    "#result = pipeline.weight(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8B9B7AE678EA4A4CB6C964B9BDDD0F7B",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for w in [[.9, .1], [.8, .2], [.7, .3]]:\n",
    "    print(w)\n",
    "    pipeline.weight(w).validate(roc_auc_score,indices=(x_train.index, x_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E170D975CD37449EA6090F836EE11E50",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = pipeline.weight([.7, .3]).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DF37F586B9824287B586B79F7A1168A6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'uid':uid_te, 'z':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2FC357A19E445BBA70C436A45D88D17",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('../result/merge2model.txt', index=None, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
